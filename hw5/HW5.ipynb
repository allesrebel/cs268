{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29b382ca",
   "metadata": {},
   "source": [
    "# Homework 5\n",
    "\n",
    "Alles Rebel\n",
    "Computational Science PhD\n",
    "\n",
    "\n",
    "\n",
    "## Intoduction!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c96e49",
   "metadata": {},
   "source": [
    "## Pre-Reqs\n",
    "\n",
    "Like other homeworks, we'll start by getting the kernel set up with the right dependencies. Running this once should do the trick for the rest of the homework;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a44f01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[92m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "   3163.9 ms\u001b[32m  ✓ \u001b[39mPlots → IJuliaExt\n",
      "  1 dependency successfully precompiled in 5 seconds. 240 already precompiled.\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.11/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "import Pkg; \n",
    "Pkg.add(\"Distributions\")\n",
    "Pkg.add(\"PrettyTables\")\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"ForwardDiff\")\n",
    "Pkg.add(\"Optim\")\n",
    "\n",
    "using Printf\n",
    "using LinearAlgebra\n",
    "using ForwardDiff\n",
    "using Random\n",
    "using Distributions\n",
    "using Statistics\n",
    "using Dates\n",
    "using PrettyTables\n",
    "using Optim\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567138ee",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "The goal of this assignment is to apply a gradient solver to a constrainted optimization problem. In this case the problem needs to be atleast 10 dimensions. The method I'll stick with is the first one suggested by the assignment: the method of Augmented Lagrangian! And we'll apply it to Booth's Function, just updated to use 10 variables instead of 2 via the chaining method introduced in HW2, 1C.\n",
    "\n",
    "### Broad Overview of Augmented Lagrangians\n",
    "In general, these methods solve optimization problems with constraints by incorporating the constraints as additional terms in the objective function. These additional terms involve new parameters, known as Lagrange multipliers, which help reformulate the constrained problem (involving equalities or inequalities) into an unconstrained one.\n",
    "\n",
    "To ensure numerical stablity - Augmented lagrangians intoduce a penality term to the discourage constraint violations. The optimization alternates between minimizing the augmented Lagrangian and updating the multipliers and penalty parameters iteratively. That's what we'll be implementing below!\n",
    "\n",
    "### Booth's Function!\n",
    "\n",
    "We'll reuse the code I wrote from the earlier homework - line for line. Originally designed to be used with existing autodiff (forwardiff in julia) and Optim package. It will suit our purposes for this homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f49599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "booths_n_gradient (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Booth's function - generalized for any number of variables\n",
    "# Uses the method suggested by Homework2 Problem 1C to chain variables\n",
    "# pair wise to extend from 2D -> ND\n",
    "# I wrote this for HW2\n",
    "function booths_n(x; n = 10)\n",
    "    result = 0.0\n",
    "    # same rationale for ending at n-1, we need the nth element for n-1\n",
    "    for i in 1:(n - 1)\n",
    "        result += ((x[i] + 2*x[i+1] - 7)^2 + (2*x[i] + x[i+1] - 5)^2)\n",
    "    end\n",
    "    return result\n",
    "end\n",
    "\n",
    "# Same with this - since the methods of HW needed gradients\n",
    "# we'll need this as well for this HW\n",
    "function booths_n_gradient(x; n = 10)\n",
    "    grad = Float64[]\n",
    "    \n",
    "    # Special case for the first element\n",
    "    push!( grad, 2*(x[1]+2*x[2]-7) + 4*(2*x[1] + x[2] - 5) )\n",
    "    \n",
    "    # Compute the gradient for the 2:n-1 elements\n",
    "    for i in 2:(n-1)\n",
    "        push!( grad, 2*(x[i]+2*x[i+1]-7) + 4*(2*x[i] + x[i+1] - 5) + 4*(x[i-1] + 2*x[i] - 7) + 2*(2*x[i-1] + x[i] - 5) )\n",
    "    end\n",
    "\n",
    "    # Special case for the last element (n-th element)\n",
    "    push!( grad, 4*(x[n-1] + 2*x[n] - 7) + 2*(2*x[n-1] + x[n] - 5) ) \n",
    "    \n",
    "    return grad\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7cff6",
   "metadata": {},
   "source": [
    "### Implemention of augmented lagrangian method\n",
    "\n",
    "This will be a bit involved, but in general - it's the following steps:\n",
    "- We'll attempt to use Julia's Optim library\n",
    "- We'll use the earlier code to compare the results of the augmented lagrangian with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae31f8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "augmented_lagrange_method (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gradient_descent(objective, x0; tol=1e-6, max_iters=1000)\n",
    "    \"\"\"\n",
    "    Gradient descent implementation using Julia's Optim library.\n",
    "    \n",
    "    \n",
    "    Parameters:\n",
    "        objective : Objective function to minimize.\n",
    "        x0        : Initial guess for optimization variables.\n",
    "        tol       : Tolerance for convergence (default: 1e-6).\n",
    "        max_iters : Maximum number of iterations (default: 1000).\n",
    "        \n",
    "    Returns:\n",
    "        x_optimal       : Optimized variables.\n",
    "        steps           : Number of iterations performed.\n",
    "        func_evals      : Total number of function evaluations.\n",
    "        grad_evals      : Total number of gradient evaluations.\n",
    "    \"\"\"\n",
    "    result = Optim.optimize(objective, x0, GradientDescent(); \n",
    "                      iterations = max_iters, \n",
    "                      g_tol = tol)\n",
    "    x_optimal = Optim.minimizer(result)\n",
    "    steps = Optim.iterations(result)\n",
    "    func_evals = Optim.f_calls(result)  # Number of function evaluations\n",
    "    grad_evals = Optim.g_calls(result)  # Number of gradient evaluations\n",
    "    return x_optimal, steps, func_evals, grad_evals\n",
    "end\n",
    "\n",
    "function augmented_lagrange_method(f, h, x, k_max; ρ=1.0, γ=2.0)\n",
    "    \"\"\"\n",
    "    Augmented Lagrange Method for constrained optimization.\n",
    "    \n",
    "    Minimizes `f` subject to `h(x) = 0`.\n",
    "    \n",
    "    Parameters:\n",
    "        f       : Objective function to minimize.\n",
    "        h       : Constraint function such that `h(x) = 0`.\n",
    "        x       : Initial guess for optimization variables.\n",
    "        k_max   : Maximum number of iterations.\n",
    "        ρ       : Initial penalty parameter (default: 1.0).\n",
    "        γ       : Penalty parameter scaling factor (default: 2.0).\n",
    "        \n",
    "    Returns:\n",
    "        x                     : Point where minimum occurs.\n",
    "        descents              : Total number of gradient descent steps performed.\n",
    "        convergence_measure   : Absolute difference between the last two \n",
    "                                minimum values of the objective function.\n",
    "    \"\"\"\n",
    "    λ = zeros(length(h(x)))               # Initialize Lagrange multipliers\n",
    "    descents = 0                          # Track total descent steps\n",
    "    old_f_value = f(x)                    # Track old objective value\n",
    "    convergence_measure = 0.0             # Convergence measure\n",
    "\n",
    "    for k in 1:k_max\n",
    "        # Define penalty function\n",
    "        penalty_function(x) = (ρ / 2) * sum(h(x).^2) - dot(λ, h(x))\n",
    "        \n",
    "        # Define augmented objective function\n",
    "        objective(x) = f(x) + penalty_function(x)\n",
    "        \n",
    "        # Optimize using steepest gradient descent\n",
    "        x, descent_steps = gradient_descent(objective, x)\n",
    "        \n",
    "        # Update convergence metrics\n",
    "        new_f_value = f(x)\n",
    "        convergence_measure = abs(new_f_value - old_f_value)\n",
    "        old_f_value = new_f_value\n",
    "\n",
    "        # Update Lagrange multipliers and penalty parameter\n",
    "        λ .= λ .- ρ * h(x)\n",
    "        ρ *= γ\n",
    "\n",
    "        # Accumulate descent steps\n",
    "        descents += descent_steps\n",
    "    end\n",
    "\n",
    "    return x, descents, convergence_measure\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d376d1",
   "metadata": {},
   "source": [
    "### Experimental Methodology\n",
    "\n",
    "We'll utilize the same testing methodology as the HW2, generating a BUNCH of random vectors to start from. And then running the method across each of the vectors, recording how many function calls, gradient calls, exectuation time and error from what the ideal solution would have been. We'll compare the above method against the earlier line search method.\n",
    "\n",
    "First we'll get the environment ready to do the experiment - how we'll generate everything an calculate the answers. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.1",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
